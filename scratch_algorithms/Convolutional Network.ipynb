{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle # saving adn loading\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for load and save model\n",
    "class LiteOCR:\n",
    "    def __init__(self, fn='alpha_weights.pkl', pool_size=2):\n",
    "        #load the weights from the pickle file and the meta data\n",
    "        [weights, meta] = pickle.load(open(fn, 'rb'), encoding='latin1')\n",
    "        #current, this class must be  init from pickle file\n",
    "        self.vocab = meta['vocab']\n",
    "        \n",
    "        self.img_rows = meta[\"img_side\"]\n",
    "        self.img_cols = meta[\"img_side\"]\n",
    "        \n",
    "        self.CNN = LiteCNN()\n",
    "        self.CNN.load_weights(weights)\n",
    "        self.CNN.pool_size = int(pool_size)\n",
    "    \n",
    "    def predict(self, image):\n",
    "        print(image.shape)\n",
    "        X = np.reshape(image, (1, 1, self.img_rows, self.img_cols))\n",
    "        X = X.astype(\"float32\")\n",
    "        \n",
    "        predicted_i = self.CNN.predict(X)\n",
    "        return self.vocab[predicted_i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteCNN:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.pool_size = None\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        assert not self.layers, \"Weights can only loaded once!\"\n",
    "        for k in range(len(weights.keys())):\n",
    "            self.layers.append(weights[\"layer_{}\".format(k)])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        h = self.cnn_layer(X, layer_i = 0, border_mode='full')\n",
    "        X = h\n",
    "        h = self.relu_layer(X)\n",
    "        X = h\n",
    "        h = self.cnn_layer(X, layer_i=2, border_mode='valid')\n",
    "        X = h\n",
    "        h = self.relu_layer(X)\n",
    "        X = h\n",
    "        h = self.maxpooling_layer(X)\n",
    "        X = h\n",
    "        h = self.dropout_layer(X, 0.25)\n",
    "        X = h\n",
    "        h = self.flatten_layer(X, layer_i=7)\n",
    "        X = h\n",
    "        h = self.dense_layer(X, fully, layer_i = 10)\n",
    "        X = h\n",
    "        h = self.softmax_layer2D(X)\n",
    "        X = h\n",
    "        max_i = self.classify(X)\n",
    "        return max_i[0]\n",
    "    \n",
    "    def maxpooling_layer(self, convolved_features):\n",
    "        nb_features = convolved_features.shape[0]\n",
    "        nb_images = convolved_features.shape[1]\n",
    "        conv_dim = convolved_features.shape[2]\n",
    "        \n",
    "        pooled_features = np.zeros((nb_features, nb_images, res_dim, res_dim))\n",
    "        \n",
    "        for image_i in range(nb_images):\n",
    "            for feature_i in range(nb_features):\n",
    "                for pool_row in range(res_dim):\n",
    "                    row_start = pool_row * self.pool_size\n",
    "                    row_end = row_start + self.pool_size\n",
    "                    \n",
    "                    for pool_col in range(res_dim):\n",
    "                        col_start = pool_col * self.pool_size\n",
    "                        col_end = col_start + self.pool_size\n",
    "                        \n",
    "                        patch = convlved_features[feature_i, image_i, row_start : row_end, col_start : col_end]\n",
    "                        pooled_features[feature_i, image_i, pool_row, pool_col] = np.max(patch)\n",
    "            return pooled_features\n",
    "        \n",
    "    def cnn_layer(self, X, layer_i = 0, border_mode=\"full\"):\n",
    "        features = self.layers[layer_i][\"param_0\"]\n",
    "        bias = self.layers[layer_i][\"param_1\"]\n",
    "        \n",
    "        patch_dim = features[0].shape[-1]\n",
    "        nb_features = features.shape[0]\n",
    "        image_dim = X.shape[2]\n",
    "        image_channels = X.shape[1]\n",
    "        nb_images = X.shape[0]\n",
    "        \n",
    "        if border_mode == 'full':\n",
    "            conv_dim = image_dim + patch_dim -1\n",
    "        elif border_mode == 'valid':\n",
    "            conv_dim = image_dim - patch_dim + 1\n",
    "        \n",
    "        convolved_features = np.zeros((nb_images, nb_features, conv_dim, conv_dim))\n",
    "        for image_i in range(nb_images):\n",
    "            for feature_i in range(nb_features):\n",
    "                convolved_image = np.zeros((conv_dim, conv_dim))\n",
    "                for channel in range(image_channels):\n",
    "                    feature = features[feature_i, channel, :, :]\n",
    "                    image = X[image_i, channel, :, :]\n",
    "                    convolved_image += self.convolve2d(image, feature, border_mode)\n",
    "                convolved_image = convolved_image + bias[feature_i]\n",
    "                convolved_features[image_i, feature_i, :, :] = convolved_image\n",
    "        return convolvrd_features\n",
    "    \n",
    "    def dense_layer(self, X, layer_i = 0):\n",
    "        W = self.layer[layer_i][\"param_0\"]\n",
    "        b = self.layers[layer_i][\"param_1\"]\n",
    "        \n",
    "        output = np.dot(X, W) + b\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    \n",
    "    def convolve2d(image, feature, border_mode=\"full\"):\n",
    "        image_dim = np.array(image.shape)\n",
    "        feature_dim = np.array(feature.shape)\n",
    "        \n",
    "        target_dim = image_dim + feature_dim - 1\n",
    "        \n",
    "        fft_result = np.fft.fft2(image, target_dim) * np.fft.fft2(feature, target_dim)\n",
    "        target = np.fft.ifft2(fft_result).real\n",
    "        \n",
    "        if border_mode == 'valid':\n",
    "            valid_dim = image_dim - feature_dim + 1\n",
    "            if np.any(valid_dim < 1):\n",
    "                valid_dim = feature_dim - image_dim + 1\n",
    "            start_i = (target_dim, valid_dim) // 2\n",
    "            end_i = start_i + valid_dim\n",
    "            target = target[start_i[0]: end_i[0], start_i[1]:end_i[1]]\n",
    "        return target\n",
    "        \n",
    "    def relu_layer(x):\n",
    "        z = np.zeros_like(x)\n",
    "        return np.where(x>z, x, z)\n",
    "    \n",
    "    def sofmax_layer2D(w):\n",
    "        maxes = np.amax(w, axis=1)\n",
    "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "        e = np.exp(w-maxes)\n",
    "        dist = e / np.sum(e, axis =1, keepdims= True)\n",
    "        return dist\n",
    "    \n",
    "    def dropout_layer(X, p):\n",
    "        retaun_prob = 1. - p\n",
    "        X *= retain_prob\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
