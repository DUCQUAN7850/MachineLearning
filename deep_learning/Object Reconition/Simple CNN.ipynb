{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN model for CIFA-10\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix randow seed for reporducibility\n",
    "seed =7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,210,090\n",
      "Trainable params: 4,210,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1. Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function and a weight constraint of max norm set to 3.\n",
    "# 2. Dropout set to 20%.\n",
    "# 3. Convolutional layer, 32 feature maps with a size of 3×3, a rectifier activation function and a weight constraint of max norm set to 3.\n",
    "# 4. Max Pool layer with size 2×2.\n",
    "# 5. Flatten layer.\n",
    "# 6. Fully connected layer with 512 units and a rectifier activation function.\n",
    "# 7. Dropout set to 50%.\n",
    "# 8. Fully connected output layer with 10 units and a softmax activation function.\n",
    "\n",
    "#create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32,(3,3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/ epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 449s - loss: 1.7174 - acc: 0.3772 - val_loss: 1.3951 - val_acc: 0.4929\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 434s - loss: 1.3374 - acc: 0.5196 - val_loss: 1.1894 - val_acc: 0.5763\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 781s - loss: 1.1631 - acc: 0.5863 - val_loss: 1.0722 - val_acc: 0.6195\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 825s - loss: 1.0357 - acc: 0.6319 - val_loss: 1.0372 - val_acc: 0.6286\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 833s - loss: 0.9350 - acc: 0.6683 - val_loss: 0.9808 - val_acc: 0.6528\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 833s - loss: 0.8468 - acc: 0.7013 - val_loss: 0.9381 - val_acc: 0.6706\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 878s - loss: 0.7775 - acc: 0.7242 - val_loss: 0.9208 - val_acc: 0.6750\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 871s - loss: 0.7105 - acc: 0.7500 - val_loss: 0.9100 - val_acc: 0.6824\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 872s - loss: 0.6523 - acc: 0.7710 - val_loss: 0.9151 - val_acc: 0.6876\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 881s - loss: 0.6042 - acc: 0.7875 - val_loss: 0.9196 - val_acc: 0.6926\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 885s - loss: 0.5517 - acc: 0.8057 - val_loss: 0.9063 - val_acc: 0.6951\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 892s - loss: 0.5113 - acc: 0.8195 - val_loss: 0.9155 - val_acc: 0.6979\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 875s - loss: 0.4738 - acc: 0.8317 - val_loss: 0.9411 - val_acc: 0.6970\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 945s - loss: 0.4420 - acc: 0.8437 - val_loss: 0.9350 - val_acc: 0.6978\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 877s - loss: 0.4105 - acc: 0.8564 - val_loss: 0.9322 - val_acc: 0.7001\n",
      "Epoch 16/25\n",
      " 4352/50000 [=>............................] - ETA: 607s - loss: 0.3383 - acc: 0.8826"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)\n",
    "# Finbal evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
