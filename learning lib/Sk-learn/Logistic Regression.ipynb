{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "Number of spam messages: 747\n",
      "Number of ham messages: 4825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                       1\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/SMSSpamCollection.csv', delimiter='\\t', header=None)\n",
    "print(df.head())\n",
    "print('Number of spam messages:', df[df[0] == 'spam'][0].count())\n",
    "print('Number of ham messages:', df[df[0] == 'ham'][0].count())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "ham\n",
      "ham\n",
      "ham\n",
      "ham\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "df = pd.read_csv('data/SMSSpamCollection.csv', delimiter='\\t', header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "for i, prediction in enumerate(predictions[:5]):\n",
    "    print(prediction)\n",
    "    #print('Prediction: %s . Message: %s' % (prediction, X_test_raw[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAD3CAYAAAAOh6G5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbPfpvS4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbabb100358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "y_test = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.title('Confucsion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred, y_true = [0,1,1,0], [1,1,1,1]\n",
    "print('Accuracy:', accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "df = pd.read_csv('data/SMSSpamCollection.csv', delimiter='\\t', header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseId      156060\n",
      "SentenceId    156060\n",
      "Phrase        156060\n",
      "Sentiment     156060\n",
      "dtype: int64\n",
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0         1           1  A series of escapades demonstrating the adage ...   \n",
      "1         2           1  A series of escapades demonstrating the adage ...   \n",
      "2         3           1                                           A series   \n",
      "3         4           1                                                  A   \n",
      "4         5           1                                             series   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n",
      "0    A series of escapades demonstrating the adage ...\n",
      "1    A series of escapades demonstrating the adage ...\n",
      "2                                             A series\n",
      "3                                                    A\n",
      "4                                               series\n",
      "5    of escapades demonstrating the adage that what...\n",
      "6                                                   of\n",
      "7    escapades demonstrating the adage that what is...\n",
      "8                                            escapades\n",
      "9    demonstrating the adage that what is good for ...\n",
      "Name: Phrase, dtype: object\n",
      "count    156060.000000\n",
      "mean          2.063578\n",
      "std           0.893832\n",
      "min           0.000000\n",
      "25%           2.000000\n",
      "50%           2.000000\n",
      "75%           3.000000\n",
      "max           4.000000\n",
      "Name: Sentiment, dtype: float64\n",
      "2    79582\n",
      "3    32927\n",
      "1    27273\n",
      "4     9206\n",
      "0     7072\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/train.tsv', header=0, delimiter='\\t')\n",
    "print(df.count())\n",
    "print(df.head())\n",
    "print(df['Phrase'].head(10))\n",
    "print(df['Sentiment'].describe())\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.509945\n",
      "3    0.210989\n",
      "1    0.174760\n",
      "4    0.058990\n",
      "0    0.045316\n",
      "Name: Sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Sentiment'].value_counts()/df['Sentiment'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fbb04abf810, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fbb04abf810, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 14, 7, 22, 19, 524325, tzinfo=tzutc()), 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'session': '6BE611298BFF418C86DADA8E26923FA4', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'6BE611298BFF418C86DADA8E26923FA4']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 14, 7, 22, 19, 524325, tzinfo=tzutc()), 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'session': '6BE611298BFF418C86DADA8E26923FA4', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'6BE611298BFF418C86DADA8E26923FA4'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 14, 7, 22, 19, 524325, tzinfo=tzutc()), 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'session': '6BE611298BFF418C86DADA8E26923FA4', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.FunctionDef object>, <_ast.Expr object>], cell_name='<ipython-input-70-a7a1dbf8814a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fbac372e160, executi..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fbab1aa8f60, file \"<ipython-input-70-a7a1dbf8814a>\", line 30>\n        result = <ExecutionResult object at 7fbac372e160, executi..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fbab1aa8f60, file \"<ipython-input-70-a7a1dbf8814a>\", line 30>, result=<ExecutionResult object at 7fbac372e160, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fbab1aa8f60, file \"<ipython-input-70-a7a1dbf8814a>\", line 30>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...n', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...v', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...of ham messages:', df[df[0] == 'ham'][0].count())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.decribe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.summary()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", 'import numpy as np\\nimport pandas as pd\\nfrom skle..._raw, y_test_raw = train_test_split(df[1], df[0])', 'import numpy as np\\nimport pandas as pd\\nfrom skle...in_raw)\\nX_test = vectorizer.transform(X_test_raw)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...nt('Prediction: %s . Message: %s' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...print('Prediction: %s . Message:' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[0]))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {5:            0                       1\ncount   557...l call later\nfreq    4825                      30, 7:            0                       1\ncount   557...l call later\nfreq    4825                      30, 11: LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 42: 3878    Sorry sir, i will call you tomorrow.  se...DID U AVE GOOD HOLIDAY?...\nName: 1, dtype: object, 59:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  }, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_test': <1393x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 4597    Carlos is down but I have to pick it up ...o please you both insid...\nName: 1, dtype: object, 'X_train': <4179x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_train_raw': 997     Yetunde i'm in class can you not run wat...hat happened in interview?\nName: 1, dtype: object, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...n', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...v', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...of ham messages:', df[df[0] == 'ham'][0].count())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.decribe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.summary()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", 'import numpy as np\\nimport pandas as pd\\nfrom skle..._raw, y_test_raw = train_test_split(df[1], df[0])', 'import numpy as np\\nimport pandas as pd\\nfrom skle...in_raw)\\nX_test = vectorizer.transform(X_test_raw)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...nt('Prediction: %s . Message: %s' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...print('Prediction: %s . Message:' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[0]))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {5:            0                       1\ncount   557...l call later\nfreq    4825                      30, 7:            0                       1\ncount   557...l call later\nfreq    4825                      30, 11: LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 42: 3878    Sorry sir, i will call you tomorrow.  se...DID U AVE GOOD HOLIDAY?...\nName: 1, dtype: object, 59:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  }, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_test': <1393x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 4597    Carlos is down but I have to pick it up ...o please you both insid...\nName: 1, dtype: object, 'X_train': <4179x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_train_raw': 997     Yetunde i'm in class can you not run wat...hat happened in interview?\nName: 1, dtype: object, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/likewise-open/FRAMGIA/sreang.rathanak/MachineLearning/MachineLearning/learning lib/Sk-learn/<ipython-input-70-a7a1dbf8814a> in <module>()\n     25     #print('Best score: %0.3f' % grid_search.best_score_)\n     26     #print('Best paramenters set:')\n     27    # best_parameters = grid_search.best_estimator_.get_params()\n     28    # for param_name in sorted(parameters.kerys()):\n     29    #     print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n---> 30 main()\n     31 \n     32 \n     33 \n     34 \n\n...........................................................................\n/home/likewise-open/FRAMGIA/sreang.rathanak/MachineLearning/MachineLearning/learning lib/Sk-learn/<ipython-input-70-a7a1dbf8814a> in main()\n     19     }\n     20     df = pd.read_csv('data/train.tsv', header=0, delimiter='\\t')\n     21     X, y = df['Phrase'], df['Sentiment'].as_matrix()\n     22     X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n     23     grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')\n---> 24     grid_search.fit(X_train, y_train)\n     25     #print('Best score: %0.3f' % grid_search.best_score_)\n     26     #print('Best paramenters set:')\n     27    # best_parameters = grid_search.best_estimator_.get_params()\n     28    # for param_name in sorted(parameters.kerys()):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]))\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...obs', refit=True, scoring='accuracy', verbose=1)>\n        X = 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object\n        y = array([2, 2, 2, ..., 3, 2, 2])\n        self.param_grid = {'clf__c': (0.1, 1, 10), 'vect__max_df': (0.25, 0.5), 'vect__ngram_range': ((1, 1), (1, 2)), 'vect__use_idf': (True, False)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Jul 14 14:22:19 2017\nPID: 22135                             Python 3.5.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]), scorer=make_scorer(accuracy_score), train=array([25437, 25457, 25488, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 27129, 27139, 27143]), verbose=1, parameters={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n    282                                      (name, self))\n    283                 sub_object = valid_params[name]\n--> 284                 sub_object.set_params(**{sub_name: value})\n        sub_object.set_params = <bound method BaseEstimator.set_params of Logist...l=0.0001,\n          verbose=0, warm_start=False)>\n        sub_name = 'c'\n        value = 0.1\n    285             else:\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), **params={'c': 0.1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'c'\n        self.__class__.__name__ = 'LogisticRegression'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter c for estimator LogisticRegression. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py\", line 1654, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py\", line 180, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py\", line 69, in _set_params\n    super(_BasePipeline, self).set_params(**params)\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/base.py\", line 284, in set_params\n    sub_object.set_params(**{sub_name: value})\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/base.py\", line 291, in set_params\n    (key, self.__class__.__name__))\nValueError: Invalid parameter c for estimator LogisticRegression. Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Jul 14 14:22:19 2017\nPID: 22135                             Python 3.5.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]), scorer=make_scorer(accuracy_score), train=array([25437, 25457, 25488, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 27129, 27139, 27143]), verbose=1, parameters={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n    282                                      (name, self))\n    283                 sub_object = valid_params[name]\n--> 284                 sub_object.set_params(**{sub_name: value})\n        sub_object.set_params = <bound method BaseEstimator.set_params of Logist...l=0.0001,\n          verbose=0, warm_start=False)>\n        sub_name = 'c'\n        value = 0.1\n    285             else:\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), **params={'c': 0.1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'c'\n        self.__class__.__name__ = 'LogisticRegression'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter c for estimator LogisticRegression. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Jul 14 14:22:19 2017\nPID: 22135                             Python 3.5.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]), scorer=make_scorer(accuracy_score), train=array([25437, 25457, 25488, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 27129, 27139, 27143]), verbose=1, parameters={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n    282                                      (name, self))\n    283                 sub_object = valid_params[name]\n--> 284                 sub_object.set_params(**{sub_name: value})\n        sub_object.set_params = <bound method BaseEstimator.set_params of Logist...l=0.0001,\n          verbose=0, warm_start=False)>\n        sub_name = 'c'\n        value = 0.1\n    285             else:\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), **params={'c': 0.1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'c'\n        self.__class__.__name__ = 'LogisticRegression'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter c for estimator LogisticRegression. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-a7a1dbf8814a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m    \u001b[0;31m# for param_name in sorted(parameters.kerys()):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m    \u001b[0;31m#     print('\\t%s: %r' % (param_name, best_parameters[param_name]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-a7a1dbf8814a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#print('Best score: %0.3f' % grid_search.best_score_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#print('Best paramenters set:')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 for train, test in cv)\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fbb04abf810, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fbb04abf810, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 14, 7, 22, 19, 524325, tzinfo=tzutc()), 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'session': '6BE611298BFF418C86DADA8E26923FA4', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'6BE611298BFF418C86DADA8E26923FA4']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 14, 7, 22, 19, 524325, tzinfo=tzutc()), 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'session': '6BE611298BFF418C86DADA8E26923FA4', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'6BE611298BFF418C86DADA8E26923FA4'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 7, 14, 7, 22, 19, 524325, tzinfo=tzutc()), 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'session': '6BE611298BFF418C86DADA8E26923FA4', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2B75AEB60A3641478A467214F3666A03', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import pandas as pd\\nfrom sklearn.feature_extract...(param_name, best_parameters[param_name]))\\nmain()', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.FunctionDef object>, <_ast.Expr object>], cell_name='<ipython-input-70-a7a1dbf8814a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fbac372e160, executi..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fbab1aa8f60, file \"<ipython-input-70-a7a1dbf8814a>\", line 30>\n        result = <ExecutionResult object at 7fbac372e160, executi..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fbab1aa8f60, file \"<ipython-input-70-a7a1dbf8814a>\", line 30>, result=<ExecutionResult object at 7fbac372e160, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fbab1aa8f60, file \"<ipython-input-70-a7a1dbf8814a>\", line 30>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...n', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...v', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...of ham messages:', df[df[0] == 'ham'][0].count())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.decribe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.summary()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", 'import numpy as np\\nimport pandas as pd\\nfrom skle..._raw, y_test_raw = train_test_split(df[1], df[0])', 'import numpy as np\\nimport pandas as pd\\nfrom skle...in_raw)\\nX_test = vectorizer.transform(X_test_raw)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...nt('Prediction: %s . Message: %s' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...print('Prediction: %s . Message:' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[0]))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {5:            0                       1\ncount   557...l call later\nfreq    4825                      30, 7:            0                       1\ncount   557...l call later\nfreq    4825                      30, 11: LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 42: 3878    Sorry sir, i will call you tomorrow.  se...DID U AVE GOOD HOLIDAY?...\nName: 1, dtype: object, 59:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  }, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_test': <1393x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 4597    Carlos is down but I have to pick it up ...o please you both insid...\nName: 1, dtype: object, 'X_train': <4179x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_train_raw': 997     Yetunde i'm in class can you not run wat...hat happened in interview?\nName: 1, dtype: object, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...n', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...v', delimiter='\\\\t', header=None)\\nprint(df.head())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...of ham messages:', df[df[0] == 'ham'][0].count())\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.decribe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...es:', df[df[0] == 'ham'][0].count())\\ndf.summary()\", \"import pandas as pd\\ndf = pd.read_csv('data/SMSSp...s:', df[df[0] == 'ham'][0].count())\\ndf.describe()\", 'import numpy as np\\nimport pandas as pd\\nfrom skle..._raw, y_test_raw = train_test_split(df[1], df[0])', 'import numpy as np\\nimport pandas as pd\\nfrom skle...in_raw)\\nX_test = vectorizer.transform(X_test_raw)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', 'import numpy as np\\nimport pandas as pd\\nfrom skle...sticRegression()\\nclassifier.fit(X_train, y_train)', \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle... %s . Message: %s' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...nt('Prediction: %s . Message: %s' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...print('Prediction: %s . Message:' % (prediction))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[i]))\", \"import numpy as np\\nimport pandas as pd\\nfrom skle...on: %s . Message:' % (prediction, X_test_raw[0]))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {5:            0                       1\ncount   557...l call later\nfreq    4825                      30, 7:            0                       1\ncount   557...l call later\nfreq    4825                      30, 11: LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 42: 3878    Sorry sir, i will call you tomorrow.  se...DID U AVE GOOD HOLIDAY?...\nName: 1, dtype: object, 59:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  }, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X_test': <1393x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 4597    Carlos is down but I have to pick it up ...o please you both insid...\nName: 1, dtype: object, 'X_train': <4179x7447 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_train_raw': 997     Yetunde i'm in class can you not run wat...hat happened in interview?\nName: 1, dtype: object, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/likewise-open/FRAMGIA/sreang.rathanak/MachineLearning/MachineLearning/learning lib/Sk-learn/<ipython-input-70-a7a1dbf8814a> in <module>()\n     25     #print('Best score: %0.3f' % grid_search.best_score_)\n     26     #print('Best paramenters set:')\n     27    # best_parameters = grid_search.best_estimator_.get_params()\n     28    # for param_name in sorted(parameters.kerys()):\n     29    #     print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n---> 30 main()\n     31 \n     32 \n     33 \n     34 \n\n...........................................................................\n/home/likewise-open/FRAMGIA/sreang.rathanak/MachineLearning/MachineLearning/learning lib/Sk-learn/<ipython-input-70-a7a1dbf8814a> in main()\n     19     }\n     20     df = pd.read_csv('data/train.tsv', header=0, delimiter='\\t')\n     21     X, y = df['Phrase'], df['Sentiment'].as_matrix()\n     22     X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n     23     grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')\n---> 24     grid_search.fit(X_train, y_train)\n     25     #print('Best score: %0.3f' % grid_search.best_score_)\n     26     #print('Best paramenters set:')\n     27    # best_parameters = grid_search.best_estimator_.get_params()\n     28    # for param_name in sorted(parameters.kerys()):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]))\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...obs', refit=True, scoring='accuracy', verbose=1)>\n        X = 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object\n        y = array([2, 2, 2, ..., 3, 2, 2])\n        self.param_grid = {'clf__c': (0.1, 1, 10), 'vect__max_df': (0.25, 0.5), 'vect__ngram_range': ((1, 1), (1, 2)), 'vect__use_idf': (True, False)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Jul 14 14:22:19 2017\nPID: 22135                             Python 3.5.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, array([2, 2, 2, ..., 3, 2, 2]), make_scorer(accuracy_score), array([25437, 25457, 25488, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 27129, 27139, 27143]), 1, {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=16811                                       Crik...ppened only yesterday\nName: Phrase, dtype: object, y=array([2, 2, 2, ..., 3, 2, 2]), scorer=make_scorer(accuracy_score), train=array([25437, 25457, 25488, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 27129, 27139, 27143]), verbose=1, parameters={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf__c': 0.1, 'vect__max_df': 0.25, 'vect__ngram_range': (1, 1), 'vect__use_idf': True})\n    279                     raise ValueError('Invalid parameter %s for estimator %s. '\n    280                                      'Check the list of available parameters '\n    281                                      'with `estimator.get_params().keys()`.' %\n    282                                      (name, self))\n    283                 sub_object = valid_params[name]\n--> 284                 sub_object.set_params(**{sub_name: value})\n        sub_object.set_params = <bound method BaseEstimator.set_params of Logist...l=0.0001,\n          verbose=0, warm_start=False)>\n        sub_name = 'c'\n        value = 0.1\n    285             else:\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/sklearn/base.py in set_params(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), **params={'c': 0.1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'c'\n        self.__class__.__name__ = 'LogisticRegression'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter c for estimator LogisticRegression. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def main():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer(stop_words='english')),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.25, 0.5),\n",
    "        'vect__ngram_range': ((1,1), (1,2)),\n",
    "        'vect__use_idf': (True, False),\n",
    "        'clf__c': (0.1, 1, 10),\n",
    "    }\n",
    "    df = pd.read_csv('data/train.tsv', header=0, delimiter='\\t')\n",
    "    X, y = df['Phrase'], df['Sentiment'].as_matrix()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    #print('Best score: %0.3f' % grid_search.best_score_)\n",
    "    #print('Best paramenters set:')\n",
    "   # best_parameters = grid_search.best_estimator_.get_params()\n",
    "   # for param_name in sorted(parameters.kerys()):\n",
    "   #     print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
